---
title: 'Scrapy'
date: 2024-01-04
permalink: /posts/2024/01/scrapy/
tags:
  - python
  - scrapy
---

# 爬虫学习笔记

## Chapter 1. Scrapy简介

scrapy优势：
1. 可以并行运行多个请求，并且通过单一线程来管理他们。
2. 可以直接使用beautiful soup、lxml，以及selectors，更高效地处理残缺的代码和编码
3. 只需编写**爬虫**和**管道**等少数模块
4. 可以同mysql、redis和elasticsearch等服务链接起来

需要规避的事情：
1. 避免DoS（拒绝服务）攻击的行为，如果发现响应时间增加了，就应该降低爬虫的强度
2. 侵犯版权（肖像权等）

在请求中，有一个User-Agent字段，让网站管理员知道你是谁，用数据做什么。如果User-Agent是一个URL或者应用名称，那么网站管理员可以访问站点，了解你是如何使用数据的。

## Chapter 2. 理解HTML和XPath

域名系统：在网络上定位合适的服务器

可以通过“查看页面源代码”看到与其相关的HTML文件（Mac可以使用Cmd+U快捷键）。源代码中的尖括号部分的内容（例如：\<p\>）称为**标签**。一对标签（例如：\<p\>与\</p\>）中的内容被称为**HTML元素**。如果一个标签中有别的键值对（例如：href=""），则键值对被称为**属性**。

唯一可见的是body元素中的内容。

XPath：选择并抽取元素、属性和文本。

在Chrome页面上右键点击【检查】，即可进入控制台，使用【$x】工具

XPath表达式中的双斜线【//a】表示获取所有该目录下的a元素，无论其在哪个层次；
单斜线【/a】仅获得该目录直接下级的a元素

访问属性时，使用@符号：【//a/@href】即为获得所有a标签中的href属性值。

【//a[@href]】可以获得包含href属性的所有a标签。

若某个标签下的内容很多，比如【//img】下有很多图片，则可以用数组的形式索引（注意，**索引从1开始**），例如【//img[1]】

为了使XPath更鲁棒，遵守几点规则：
1. 避免使用数组索引【解决方法：找其上级的id或class属性】
2. 避免使用经常更换的class【解决方法：识别出与CSS相关的class，尽可能不使用它】
3. 尽可能使用ID属性
4. 尽可能使用面向数据内容的class，例如class=departure-time


## Chapter 3. 爬虫基础






## Chapter 4. 从Scrapy到移动应用




## Chapter 5. 迅速的爬虫技巧



## Chapter 6. 部署到Scrapinghub






## Chapter 7. 配置与管理






## Chapter 8. Scrapy编程








## Chapter 9. 管道秘诀









## Chapter 10. 理解Scrapy性能








## Chapter 11. 使用Scrapyd与实时分析进行分布式爬取














