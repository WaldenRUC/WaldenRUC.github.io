---
title: 'LLMBox'
date: 2024-07-11
permalink: /posts/2024/07/llmbox/
tags:
  - Pytorch
  - Python
---
# LLMBox学习笔记

## 本文主要记录LLMBox框架的阅读笔记。主要内容参考[LLMBox文档](https://github.com/RUCAIBox/LLMBox)、[deepspeed博客](https://github.com/bobo0810/LearnDeepSpeed)和[官方文档1](https://github.com/microsoft/DeepSpeed/blob/master/blogs/deepspeed-ucp/chinese/README.md)，[官方文档2](https://www.deepspeed.ai/getting-started/)


### 为什么要学习大模型训练框架？

大模型的训练非常耗时，因此加速训练并且保存模型训练的中间状态非常关键，如果训练失败则可以从某个检查点开始继续训练，并且可以评估模型在训练的不同阶段的性能。这样可以更灵活地调整超参数，以及对下游任务的微调。在推理阶段，大模型也可以通过KVCache等方式实现加速。这些复杂的操作引发了对统一的大模型训练和推理框架的需求。LLMBox统一了训练、评估和推理等生成式大模型框架，因此掌握LLMBox就能够掌握运用大模型开展科学研究。对于BERT等编码模型，可以用huggingface-trainer框架进行训练。

### 数据集和模型加载
在下载huggingface数据集的时候，目标地址可能被墙，下载不了，例如：
```shell
https://huggingface.co/datasets/databricks/databricks-dolly-15k/resolve/main/databricks-dolly-15k.jsonl
```
此时可以将前缀https://huggingface.co替换成https://hf-mirror.com，用国内的镜像站下载。
可以用[huggingface-cli方法](https://hf-mirror.com/)下载huggingface模型和数据集到指定的目录下。

















train_batch_size为总batch_size，它由单张卡的批次大小、梯度累积次数和GPU的数量相乘得到。

zero优化的效率是一个trade-off。zero-0可被视为DDP，而此时是速度最快但显存占用最多；zero-3速度最慢但显存占用最少。在a800的条件下可以使用zero-1。

### 模型训练结合swanlab看板

在训练中，有太多需要跟踪的超参数和设置，因此我们可以利用swanlab的服务，这里简单介绍一下如何使用swanlab。[swanlab](https://swanlab.cn/)是wandb的平替，但wandb由国外团队开发，因此可能存在被墙以及数据无法上传的问题。

首先，在虚拟环境中下载swanlab并且登录，注册并使用swanlab [apikey](https://swanlab.cn/settings)：
```shell
pip install swanlab
swanlab login
```
可以使用swanlab login --relogin重新登录。
关于需要记录的内容，可以分为下列几个部分：
1. swanlab.init(): project: 指定日志记录在swanlab中的哪个项目下，experiment_name: 实验名称，description: 关于实验的描述，config: 有关超参数的字典（后续可以通过swanlab.config.learning_rate=0.1的形式修改，或者直接将config字段设置成包含实验设置的json文件路径【config="swanlab-init-config.json"】），最便捷的方式是传入argparse，即args=parser.parse_args(); config=args 
2. swanlab.log(): 以字典的形式记录训练过程中每一步的loss, acc等输出，并自动生成图表。注意这里字典的值必须为int、float或swanlab多媒体类。每一个键在每一次记录时自动累积到该键的历史中。可以通过"val/loss"的方式，将loss记录到val分组内。step参数可以指定该字典记录到哪个step下。多媒体类可以选择图片、音频或文本。以文本为例，可以通过swanlab.Text("example", caption=f'{i}')转换，再通过swanlab.log()的字典值记录。

提升效率的tricks：
1. 减少指标种类的数量：通过日志记录的指标种类如果太多（>10k），则可能拖慢渲染的速度。对于每个指标，建议记录点<50k。

#### accelerate+swanlab

```python
from swanlab.integration.accelerate import SwanLabTracker
from accelerate import Accelerator

...

# 创建SwanLab日志记录器
tracker = SwanLabTracker("YOUR_SMART_PROJECT_NAME")
# 传入Accelerator
accelerator = Accelerator(log_with=tracker)

# 初始化所有日志记录器
accelerator.init_trackers("YOUR_SMART_PROJECT_NAME", config=config)

# 在训练过程中记录
accelerator.log({"training_loss": loss, "epoch_num": ep})
```

#### trainer+swanlab
```python
from swanlab.integration.huggingface import SwanLabCallback
from transformers import Trainer, TrainingArguments

...

# 实例化SwanLabCallback，只需指定project名称
swanlab_callback = SwanLabCallback(project="hf-visualization")

trainer = Trainer(
    ...
    # 传入callbacks参数
    callbacks=[swanlab_callback],
)

trainer.train()
```
具体案例：
```python
import evaluate
import numpy as np
import swanlab
from swanlab.integration.huggingface import SwanLabCallback
from datasets import load_dataset
from transformers import AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments


def tokenize_function(examples):
    return tokenizer(examples["text"], padding="max_length", truncation=True)


def compute_metrics(eval_pred):
    logits, labels = eval_pred
    predictions = np.argmax(logits, axis=-1)
    return metric.compute(predictions=predictions, references=labels)


dataset = load_dataset("yelp_review_full")

tokenizer = AutoTokenizer.from_pretrained("bert-base-cased")

tokenized_datasets = dataset.map(tokenize_function, batched=True)

small_train_dataset = tokenized_datasets["train"].shuffle(seed=42).select(range(1000))
small_eval_dataset = tokenized_datasets["test"].shuffle(seed=42).select(range(1000))

metric = evaluate.load("accuracy")

model = AutoModelForSequenceClassification.from_pretrained("bert-base-cased", num_labels=5)

training_args = TrainingArguments(
    output_dir="test_trainer",
    # 如果只需要用SwanLab跟踪实验，则将report_to参数设置为”none“
    report_to="none",
    num_train_epochs=3,
    logging_steps=50,
)

# 实例化SwanLabCallback
swanlab_callback = SwanLabCallback(experiment_name="TransformersTest")

trainer = Trainer(
    model=model,
    args=training_args,
    train_dataset=small_train_dataset,
    eval_dataset=small_eval_dataset,
    compute_metrics=compute_metrics,
    # 传入callbacks参数
    callbacks=[swanlab_callback],
)

trainer.train()
```
可以通过继承callback自定义生命周期回调函数，例如在每个epoch结束之后，推理测试集并计算指标：
```python
class NLPSwanLabCallback(SwanLabCallback):    
    def on_epoch_end(self, args, state, control, **kwargs):
	# 测试集
        test_text_list = ["example1", "example2"]
        log_text_list = []
        for text in test_text_list:
            result = model(text)
            log_text_list.append(swanlab.Text(result))
        # 在该epoch结束时的step，记录在测试集上的推理结果
        swanlab.log({"Prediction": test_text_list}, step=state.global_step)
```
